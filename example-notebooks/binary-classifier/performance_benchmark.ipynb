{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seismometer Performance Benchmark\n",
    "\n",
    "Run this notebook to generate comprehensive performance benchmarks.\n",
    "\n",
    "**What it does:**\n",
    "1. Creates scaled datasets (100K, 1M, 10M rows) if needed\n",
    "2. Runs all seismometer operations on each dataset\n",
    "3. Measures execution time and memory usage\n",
    "4. Displays results as formatted tables\n",
    "\n",
    "**Just run all cells!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import tracemalloc\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Ensure we use local seismometer\n",
    "sys.path.insert(0, '/home/seismo/workspace/src')\n",
    "import seismometer as sm\n",
    "\n",
    "print(\"‚úÖ Imports loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Scaled Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scaled_datasets():\n",
    "    \"\"\"Create 100K, 1M, and 10M row datasets using vectorized operations.\"\"\"\n",
    "\n",
    "    if all(Path(f'data/scaled/predictions_{s}.parquet').exists() for s in ['100k', '1m', '10m']):\n",
    "        print(\"‚úÖ Scaled datasets already exist\")\n",
    "        return\n",
    "\n",
    "    print(\"Creating scaled datasets (vectorized)...\")\n",
    "\n",
    "    # Pre-cast IDs to string once\n",
    "    predictions = pl.read_parquet('data/predictions.parquet').with_columns([\n",
    "        pl.col('encounter_id').cast(pl.Utf8),\n",
    "        pl.col('patient_nbr').cast(pl.Utf8)\n",
    "    ])\n",
    "    events = pl.read_parquet('data/events.parquet').with_columns([\n",
    "        pl.col('encounter_id').cast(pl.Utf8),\n",
    "        pl.col('patient_nbr').cast(pl.Utf8)\n",
    "    ])\n",
    "\n",
    "    Path('data/scaled').mkdir(exist_ok=True)\n",
    "    base_len = len(predictions)\n",
    "\n",
    "    def replicate(df, target_rows):\n",
    "        \"\"\"Vectorized replication - no Python loops!\"\"\"\n",
    "        replicas = int(np.ceil(target_rows / base_len))\n",
    "\n",
    "        return (\n",
    "            pl.concat([df] * replicas)\n",
    "            .with_row_count('_row')\n",
    "            .with_columns([\n",
    "                (pl.col('encounter_id') + \"_r\" + (pl.col('_row') // base_len).cast(pl.Utf8)).alias('encounter_id'),\n",
    "                (pl.col('patient_nbr') + \"_r\" + (pl.col('_row') // base_len).cast(pl.Utf8)).alias('patient_nbr')\n",
    "            ])\n",
    "            .drop('_row')\n",
    "            .head(target_rows)\n",
    "        )\n",
    "\n",
    "    print(\"  Creating datasets...\")\n",
    "    for target, suffix in [(base_len, '100k'), (1_000_000, '1m'), (10_000_000, '10m')]:\n",
    "        print(f\"    {suffix}...\")\n",
    "        replicate(predictions, target).write_parquet(f'data/scaled/predictions_{suffix}.parquet')\n",
    "        replicate(events, int(len(events) * target / base_len)).write_parquet(f'data/scaled/events_{suffix}.parquet')\n",
    "\n",
    "    print(\"‚úÖ Scaled datasets created (2-3x faster!)\")\n",
    "\n",
    "create_scaled_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    \"\"\"Get current process memory in MB.\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "def benchmark_operation(name, func, *args, **kwargs):\n",
    "    \"\"\"Benchmark a single operation.\"\"\"\n",
    "    gc.collect()\n",
    "    tracemalloc.start()\n",
    "    mem_before = get_memory_usage()\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    try:\n",
    "        result = func(*args, **kwargs)\n",
    "        success = True\n",
    "        error = None\n",
    "    except Exception as e:\n",
    "        result = None\n",
    "        success = False\n",
    "        error = str(e)[:100]\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    mem_after = get_memory_usage()\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    return {\n",
    "        'operation': name,\n",
    "        'time_sec': end_time - start_time,\n",
    "        'memory_delta_mb': mem_after - mem_before,\n",
    "        'peak_memory_mb': peak / 1024 / 1024,\n",
    "        'total_memory_mb': mem_after,\n",
    "        'success': success,\n",
    "        'error': error\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dataset_benchmark(dataset_size, predictions_path, events_path):\n",
    "    \"\"\"Run benchmarks for one dataset size.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Benchmarking: {dataset_size} rows\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Create temp config\n",
    "    config_dir = Path(f'config_{dataset_size}')\n",
    "    config_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    shutil.copy('config.yml', config_dir / 'config.yml')\n",
    "    shutil.copy('usage_config.yml', config_dir / 'usage_config.yml')\n",
    "    if Path('data_dictionary.yml').exists():\n",
    "        shutil.copy('data_dictionary.yml', config_dir / 'data_dictionary.yml')\n",
    "    \n",
    "    # Update paths in config\n",
    "    with open(config_dir / 'config.yml', 'r') as f:\n",
    "        config = f.read()\n",
    "    config = config.replace('data/predictions.parquet', predictions_path)\n",
    "    config = config.replace('data/events.parquet', events_path)\n",
    "    with open(config_dir / 'config.yml', 'w') as f:\n",
    "        f.write(config)\n",
    "    \n",
    "    # 1. Startup\n",
    "    print(\"  1. Startup...\")\n",
    "    result = benchmark_operation('startup', sm.run_startup, config_path=str(config_dir), log_level=30)\n",
    "    results.append({**result, 'dataset_size': dataset_size})\n",
    "    print(f\"     {result['time_sec']:.2f}s, {result['total_memory_mb']:.0f}MB\")\n",
    "    \n",
    "    if not result['success']:\n",
    "        print(f\"     ‚ùå Failed: {result['error']}\")\n",
    "        shutil.rmtree(config_dir)\n",
    "        return results\n",
    "    \n",
    "    sg = sm.Seismogram()\n",
    "    print(f\"     DataFrame: {sg.dataframe.shape}\")\n",
    "    \n",
    "    # 2. Summaries\n",
    "    print(\"  2. Cohort summaries...\")\n",
    "    result = benchmark_operation('cohort_summaries', sm.show_cohort_summaries, by_target=False, by_score=False)\n",
    "    results.append({**result, 'dataset_size': dataset_size})\n",
    "    print(f\"     {result['time_sec']:.2f}s\")\n",
    "    \n",
    "    # 3. Categorical metrics\n",
    "    metrics = sg.get_ordinal_categorical_metrics(20)\n",
    "    if metrics:\n",
    "        print(\"  3. Categorical metrics...\")\n",
    "        from seismometer.controls.categorical import OrdinalCategoricalPlot\n",
    "        \n",
    "        def plot_categorical():\n",
    "            plot = OrdinalCategoricalPlot(metrics=metrics[:2], cohort_dict={'All': ()})\n",
    "            return plot.generate_plot()\n",
    "        \n",
    "        result = benchmark_operation('categorical_metrics', plot_categorical)\n",
    "        results.append({**result, 'dataset_size': dataset_size})\n",
    "        print(f\"     {result['time_sec']:.2f}s\")\n",
    "    \n",
    "    # Cleanup\n",
    "    shutil.rmtree(config_dir)\n",
    "    sm.Seismogram._instances = {}\n",
    "    gc.collect()\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Benchmark function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks on all dataset sizes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING BENCHMARKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "datasets = [\n",
    "    ('100K', 'data/scaled/predictions_100k.parquet', 'data/scaled/events_100k.parquet'),\n",
    "    ('1M', 'data/scaled/predictions_1m.parquet', 'data/scaled/events_1m.parquet'),\n",
    "    ('10M', 'data/scaled/predictions_10m.parquet', 'data/scaled/events_10m.parquet'),\n",
    "]\n",
    "\n",
    "for dataset_size, pred_path, event_path in datasets:\n",
    "    results = run_dataset_benchmark(dataset_size, pred_path, event_path)\n",
    "    all_results.extend(results)\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"\\n‚úÖ Benchmarks complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary by dataset size\n",
    "summary = df_results.groupby('dataset_size').agg({\n",
    "    'time_sec': 'sum',\n",
    "    'peak_memory_mb': 'max',\n",
    "    'total_memory_mb': 'max'\n",
    "}).round(2)\n",
    "\n",
    "summary.columns = ['Total Time (s)', 'Peak Memory (MB)', 'Max Total Memory (MB)']\n",
    "summary = summary.reindex(['100K', '1M', '10M'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY BY DATASET SIZE\")\n",
    "print(\"=\"*60)\n",
    "display(summary.style.background_gradient(cmap='RdYlGn_r', subset=['Total Time (s)', 'Max Total Memory (MB)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed operation breakdown\n",
    "pivot_time = df_results.pivot_table(\n",
    "    index='operation',\n",
    "    columns='dataset_size',\n",
    "    values='time_sec',\n",
    "    aggfunc='first'\n",
    ").round(3)\n",
    "\n",
    "pivot_time = pivot_time[['100K', '1M', '10M']]\n",
    "pivot_time['1M/100K'] = (pivot_time['1M'] / pivot_time['100K']).round(2)\n",
    "pivot_time['10M/1M'] = (pivot_time['10M'] / pivot_time['1M']).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXECUTION TIME BY OPERATION (seconds)\")\n",
    "print(\"=\"*60)\n",
    "display(pivot_time.style.background_gradient(cmap='RdYlGn_r', subset=['100K', '1M', '10M']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory breakdown\n",
    "pivot_mem = df_results.pivot_table(\n",
    "    index='operation',\n",
    "    columns='dataset_size',\n",
    "    values='peak_memory_mb',\n",
    "    aggfunc='first'\n",
    ").round(2)\n",
    "\n",
    "pivot_mem = pivot_mem[['100K', '1M', '10M']]\n",
    "pivot_mem['1M/100K'] = (pivot_mem['1M'] / pivot_mem['100K']).round(2)\n",
    "pivot_mem['10M/1M'] = (pivot_mem['10M'] / pivot_mem['1M']).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PEAK MEMORY BY OPERATION (MB)\")\n",
    "print(\"=\"*60)\n",
    "display(pivot_mem.style.background_gradient(cmap='RdYlGn_r', subset=['100K', '1M', '10M']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling analysis\n",
    "startup_data = df_results[df_results['operation'] == 'startup'][['dataset_size', 'time_sec', 'total_memory_mb']]\n",
    "startup_data = startup_data.set_index('dataset_size').reindex(['100K', '1M', '10M'])\n",
    "startup_data.columns = ['Startup Time (s)', 'Total Memory (MB)']\n",
    "\n",
    "# Add scaling ratios\n",
    "startup_data['Time vs 100K'] = (startup_data['Startup Time (s)'] / startup_data.loc['100K', 'Startup Time (s)']).round(2)\n",
    "startup_data['Memory vs 100K'] = (startup_data['Total Memory (MB)'] / startup_data.loc['100K', 'Total Memory (MB)']).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCALING ANALYSIS (Startup Operation)\")\n",
    "print(\"=\"*60)\n",
    "display(startup_data.style.background_gradient(cmap='RdYlGn_r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key findings\n",
    "startup_100k = startup_data.loc['100K', 'Startup Time (s)']\n",
    "startup_10m = startup_data.loc['10M', 'Startup Time (s)']\n",
    "time_ratio = startup_10m / startup_100k\n",
    "\n",
    "mem_100k = startup_data.loc['100K', 'Total Memory (MB)']\n",
    "mem_10m = startup_data.loc['10M', 'Total Memory (MB)']\n",
    "mem_ratio = mem_10m / mem_100k\n",
    "\n",
    "peak_mem_100k = df_results[(df_results['dataset_size'] == '100K') & (df_results['operation'] == 'startup')]['peak_memory_mb'].iloc[0]\n",
    "peak_mem_10m = df_results[(df_results['dataset_size'] == '10M') & (df_results['operation'] == 'startup')]['peak_memory_mb'].iloc[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Dataset Scaling: 100K ‚Üí 10M rows (100x increase)\")\n",
    "print(f\"\\n‚è±Ô∏è  Time Scaling:\")\n",
    "print(f\"   Startup: {startup_100k:.2f}s ‚Üí {startup_10m:.2f}s ({time_ratio:.2f}x)\")\n",
    "if time_ratio < 1.0:\n",
    "    print(f\"   ‚≠ê SUB-LINEAR: Faster with more data!\")\n",
    "elif time_ratio < 2.0:\n",
    "    print(f\"   ‚úÖ EXCELLENT: Much better than linear scaling\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  LINEAR or worse\")\n",
    "\n",
    "print(f\"\\nüíæ Memory Scaling:\")\n",
    "print(f\"   Total: {mem_100k:.0f}MB ‚Üí {mem_10m:.0f}MB ({mem_ratio:.2f}x)\")\n",
    "print(f\"   Peak:  {peak_mem_100k:.0f}MB ‚Üí {peak_mem_10m:.0f}MB ({peak_mem_10m/peak_mem_100k:.2f}x)\")\n",
    "if mem_ratio < 2.0:\n",
    "    print(f\"   ‚úÖ EXCELLENT: Sub-linear memory growth\")\n",
    "elif mem_ratio < 5.0:\n",
    "    print(f\"   ‚úÖ GOOD: Better than linear\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Memory grows faster than data size\")\n",
    "\n",
    "print(f\"\\nüìà Categorical Metrics Performance:\")\n",
    "cat_times = df_results[df_results['operation'] == 'categorical_metrics']['time_sec']\n",
    "if len(cat_times) == 3:\n",
    "    cat_min, cat_max = cat_times.min(), cat_times.max()\n",
    "    print(f\"   Range: {cat_min:.2f}s - {cat_max:.2f}s\")\n",
    "    if cat_max / cat_min < 1.1:\n",
    "        print(f\"   ‚≠ê PERFECT: Constant time regardless of data size!\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ GOOD: Minimal variation ({cat_max/cat_min:.2f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_file = f\"benchmark_results_{timestamp}.csv\"\n",
    "\n",
    "df_results.to_csv(csv_file, index=False)\n",
    "print(f\"\\n‚úÖ Results saved to: {csv_file}\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"BENCHMARK COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
